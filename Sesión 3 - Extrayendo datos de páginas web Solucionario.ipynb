{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 3 - Aprendamos a extraer datos de una página web\n",
    "\n",
    "En esta sesión pondremos las cosas que hemos aprendido de `Python` en práctica. Desarrollaremos una serie de comandos simples que nos permitan extraer las partes que deseamos de las páginas web. Los objetivos de esta sesión son:\n",
    "\n",
    "* Aprender la estructura básica de una página web.\n",
    "* Aprender a identificar elementos de CSS que nos facilitan la tarea de extracción de datos.\n",
    "* Identificar cómo obtener elementos de una tabla que está publicada en una página web. \n",
    "* Guardar información extraída en formato CSV. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Estructura básica de una página web\n",
    "\n",
    "Las páginas web están escritas en un lenguaje de escritura conocido como `HTML`. El `HTML` provee el esqueleto de la página web a las que después se les puede añadir elementos de estilo y programación. Saber la manera en que funciona `HTML` es esencial para saber la manera en que podemos extraer información de las páginas. De manera simple, `HTML` puede definirse como un conjunto de etiquetas y atributos que detallan cómo se verán los elementos de la página web. \n",
    "\n",
    "Abajo tienes una página web muy simple. Mira la manera en que está dispuesto el `HTML` [Haz doble click o enter en esta celda para que veas el código `HTML`]:\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>Page Title</title>\n",
    "\t</head>\n",
    "<body>\n",
    "\n",
    "\t<h1>Mi Primer Título</h1>\n",
    "\t<p>Este es mi primer párrafo.</p>\n",
    "\t<a href=\"http://jlcoto.github.io/taller_python/\">Este es un link al blog</a>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "Si quieres, puedes escribir tu propio `HTML` y ver cómo se modifica automáticamente [en la siguiente página](http://www.w3schools.com/html/tryit.asp?filename=tryhtml_default).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más que HTML\n",
    "\n",
    "Las páginas web modernas distan mucho de la simple página previamente mostrada. Normalmente las acompañan muchas reglas de estilo y algunas características que permiten al usuario interactuar con alguna plataforma. El código de `HTML` de mi repositorio llamado `index_tables.html` presenta una tabla. Nota que esta tabla está acompañado de reglas que permiten mejorar su estilo. Estas reglas se conocen como `CSS`. Exploremos el archivo antes de entrar a la extracción de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraigamos información de una página web\n",
    "\n",
    "Junto a los archivos que he anexado para la sesión de hoy encontrarás la página `html_basics.html`. Esta será la primera página web de la que extraigamos información. Para extraer la información de páginas web, usaremos el módulo de `Python` llamado `BeautifulSoup`. Esto hará la labor de extraer data mucho más sencilla. Asegúrate de haber descargado el módulo y de que está funcionando correctamente. Podrás leer más sobre el funcionamiento de BeautifulSoup [leyendo su documentación](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>Mi Primer Título</h1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup #Así se importa el módulo que queremos usar\n",
    "\n",
    "pag_web = open('html_basics.html', 'r').read() #con esto le decimos a Python que lea la pag web\n",
    "bsObj = BeautifulSoup(pag_web, \"html.parser\") # Acá creamos un objeto\n",
    "bsObj.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi Primer Título'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.h1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Imprime el segundo y tercer títulos de la página. Imprimelos sin las etiquetas `HTML`.\n",
    "2. Imprime la primera lista la de Jamón, Queso, Pan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find y FindAll\n",
    "\n",
    "Dos de los métodos más usados de BeautifulSoup son el `find` y `findAll`. El método `find` buscará la primera coincidencia de aquello que estés buscando. El findAll navegará toda la página web y te dara una **lista** que contiene todos aquellos elementos que concuerden con aquello que has solitado. Fíjate abajo y mira la diferencia entre qué obtenemos con `find` y `findAll` para obtener las listas de viñetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ol>\n",
      "<li>Jamón</li><li>Queso</li><li>Pan</li>\n",
      "</ol>\n"
     ]
    }
   ],
   "source": [
    "primera_lista = bsObj.find(\"ol\")\n",
    "print(primera_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ol>\n",
      "<li>Jamón</li>\n",
      "<li>Queso</li>\n",
      "<li>Pan</li>\n",
      "</ol>, <ol>\n",
      "<li>Lechuga</li>\n",
      "<li>Tomate</li>\n",
      "</ol>]\n"
     ]
    }
   ],
   "source": [
    "todas_viñetas = bsObj.findAll(\"ol\")\n",
    "print(todas_viñetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cómo accedemos a la segunda lista? Utiliza tus conocimientos de listas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagínate que queremos poner todos los productos de la primera lista en una lista de compras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>Jamón</li>, <li>Queso</li>, <li>Pan</li>]\n"
     ]
    }
   ],
   "source": [
    "mi_primera_lista = bsObj.findAll(\"ol\")[0].findAll(\"li\")\n",
    "print(mi_primera_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota dos cosas del código anterior:\n",
    "1. Puedes seguir usando llamando los métodos de BeautifulSoup sobre los elementos de la lista.\n",
    "2. Como has usado el método `findAll` dos veces, al final también obtienes una lista. \n",
    "\n",
    "Sin embargo, lo ideal al momento de guardar la data es hacerlo sin todas esas moletas etiquetas de `HTML`. ¿Qué creen que podemos hacer para eliminarlas? Si estaban pensando en usar loops, pues ¡están en lo correcto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jamón', 'Queso', 'Pan']\n"
     ]
    }
   ],
   "source": [
    "primera_lista = []\n",
    "for producto in mi_primera_lista:\n",
    " \tprimera_lista.append(producto.get_text())\n",
    "print(primera_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Ejercicios\n",
    "1. Modifica el código anterior para obtener y pon en una lista todos los elementos de la segunda lista. Estos elementos deberán formar parte de una lista llamada `segunda_lista` y no debe contener etiquetas `HTML`. Al final, haz una lista de compras finales que contenga la primera y segunda listas.\n",
    "2. Realiza el mismo ejercicio para la lista enumerada.\n",
    "Luego de trabajar el archivo `HTML` no te olvides de cerrarlo con `pag_web.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraigamos tablas\n",
    "\n",
    "A veces tenemos la suerte de que aquello que necesitamos se encuentra en una tabla en una página web. Lastimosamente, el formato en el que se encuentra los datos de la página hace imposible que podamos trabajar con ellos. Como siempre, antes de entrar a extraer cualquier elemento de una página web, lo mejor es familiarizarte con su contenido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pag_web_2 = open('index_tables.html', 'r').read()\n",
    "bsObj2 = BeautifulSoup(pag_web_2, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<th scope=\"col\">Nombre</th>, <th scope=\"col\">Correo Electrónico</th>, <th scope=\"col\">Posición</th>]\n"
     ]
    }
   ],
   "source": [
    "print(bsObj2.findAll(\"table\")[0].findAll(\"th\", {\"scope\": \"col\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<th scope=\"col\">Nombre</th>, <th scope=\"col\">Correo Electrónico</th>, <th scope=\"col\">Posición</th>]\n"
     ]
    }
   ],
   "source": [
    "print(bsObj2.find(\"table\").find(\"thead\").findAll(\"th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<th scope=\"row\">José Coto</th>, <th scope=\"row\">Héctor Barro</th>, <th scope=\"row\">Matías Buitrago</th>, <th scope=\"row\">Nicolás García</th>]\n"
     ]
    }
   ],
   "source": [
    "print(bsObj2.find(\"table\").find(\"tbody\").findAll(\"th\", {\"scope\": \"row\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td>jose.coto@pucp.pe</td>, <td>Instructor</td>, <td>hbarro_inv@example.com</td>, <td>Desarrollador</td>, <td>mbuitrago@example.com</td>, <td>Jefe</td>, <td>ngarcia@example.com</td>, <td>Jefe</td>]\n"
     ]
    }
   ],
   "source": [
    "print(bsObj2.find(\"table\").find(\"tbody\").findAll(\"td\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "1. Ahora, realiza el mismo ejercicio para la tabla 2. Primero, genera una lista con el nombre de todos las personas que aparecen en la lista. Finalmente, remueve todas las etiquetas de `HTML` de la lista final.\n",
    "2. Necesito una lista con todos los puestos y correos electrónicos de los mails obtenidos. Nuevamente, esta lista no debe contener ningún tipo de etiquetas de `HTML`.\n",
    "\n",
    "No te olvides de cerrar el archivo `pag_web_2.close()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Vamos a la web!\n",
    "\n",
    "Hasta ahora solo hemos extraído contenido de páginas web que he creado. ¿Qué pasa cuando vamos a la jungla de la web? En el siguiente ejercicio haremos lo mismo pero usando el módulo `Requests`de `Python`. Este módulo nos permitirá analzar contenido de páginas web dentro de `Python`. Puedes leer un poco más de esta librería en la [siguiente página web](http://www.python-requests.org/en/latest/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"es\">Partidos políticos del Perú</h1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "pag_wiki = requests.get(\"https://es.wikipedia.org/wiki/Partidos_pol%C3%ADticos_del_Per%C3%BA\")\n",
    "wiki_pag = BeautifulSoup(pag_wiki.text, \"html.parser\")\n",
    "\n",
    "#Agarremos el título de la página:\n",
    "wiki_pag.find(\"h1\", {\"class\":\"firstHeading\", \"lang\":\"es\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partidos políticos en el Perú'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agarremos el título de la tabla\n",
    "wiki_pag.find(\"caption\").b.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Jurado_Nacional_de_Elecciones'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtengamos el link del Jurado Nacional de Elecciones\n",
    "wiki_pag.find(\"div\", {\"id\": \"mw-content-text\"}).find(\"p\").find(\"a\").attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios:\n",
    "Utiliza lo que sabes hasta ahora para explorar un poco más la página de wikipedia.\n",
    "1. Haz una lista donde incluyas todas las coaliciones políticas que existen en el Perú.\n",
    "2. Haz una lista con las páginas que wikipedia recomienda visitar. (Bajo la sección de véase también)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## No está todo dicho\n",
    "\n",
    "A veces hay páginas que son más difíciles de extraer. Esto puede deberse a que el `HTML` que usan no está bien formateado, la falta de orden o que, simplemente, no existen tags suficientes con los cuales poder identificar los datos que deseamos. Fíjate en el ejercicio de abajo. Se nos pide obtener una lista de los partidos políticos del Perú. Es decir, lo único que deseamos extraer es una columna del cuadro. ¿Se les ocurre alguna manera de hacerlo?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acción Popular\n",
      "Alianza para el Progreso\n",
      "Democracia Directa\n",
      "Fuerza Popular\n",
      "Orden\n",
      "Partido Aprista Peruano\n",
      "Partido Democrático Somos Perú\n",
      "Partido Humanista Peruano\n",
      "Partido Nacionalista Peruano\n",
      "Partido Popular Cristiano\n",
      "Perú Patria Segura\n",
      "Perú Posible\n",
      "Peruanos Por el Kambio\n",
      "Restauración Nacional\n",
      "Siempre Unidos\n",
      "Solidaridad Nacional\n",
      "Tierra y Libertad\n",
      "Todos por el Perú\n",
      "Unión por el Perú\n",
      "Vamos Perú\n"
     ]
    }
   ],
   "source": [
    "for item in wiki_pag.find(\"table\").findAll(\"tr\"):\n",
    "    if item.td == None:\n",
    "        continue\n",
    "    else:\n",
    "        print(item.td.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acción Popular\n",
      "Alianza para el Progreso (Perú)\n",
      "Fuerza 2011\n",
      "Ántero Flores-Aráoz\n",
      "Partido Aprista Peruano\n",
      "Partido Democrático Somos Perú\n",
      "Partido Humanista Peruano\n",
      "Partido Nacionalista Peruano\n",
      "Partido Popular Cristiano\n",
      "Perú Patria Segura\n",
      "Perú Posible\n",
      "Pedro Pablo Kuczynski\n",
      "Restauración Nacional (Perú)\n",
      "Partido Solidaridad Nacional\n",
      "Tierra y Libertad (Perú)\n",
      "Unión por el Perú\n"
     ]
    }
   ],
   "source": [
    "for item in wiki_pag.find(\"table\").findAll(\"a\"):\n",
    "    try:\n",
    "        print(item.attrs[\"title\"])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML es una familia...\n",
    "\n",
    "Veámos nuevamente nuestras páginas de `HTML`. Los elementos de `HTML` también se pueden ver como una familia. Esto nos puede facilitar la vida cuando no tengamos mayor referencia para extraer un elemento, salvo por su relación con otro elemento. BeautifulSoup nos ofrece una serie de métodos para poder acceder a elementos de las páginas web por sus *\"relaciones de parentesco\"*.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bajando en el árbol familiar\n",
    "\n",
    "Existen dos métodos para bajar en el árbol familiar. `.descendants` y `.children`.\n",
    "\n",
    "*  ** .descendants **: Retorna todo el contenido que esté bajo la etiqueta padre. \n",
    "*  ** .children **: Retorna solamente el primer hijo de todo aquello que se encuentre bajo la etiqueta padre.\n",
    "\n",
    "Revisitemos algunos de nuestros ejercicios anteriores..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "pag_web = open('html_basics.html', 'r').read()\n",
    "bsObj = BeautifulSoup(pag_web, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<h1>Mi Primer Título</h1>\n",
      "Mi Primer Título\n",
      "\n",
      "sssss\n",
      "\t\n",
      "<h2> También puedo generar una serie de listas</h2>\n",
      " También puedo generar una serie de listas\n",
      "\n",
      "\n",
      "\tLista de compras (ordenadas):\n",
      "\t\n",
      "<ol>\n",
      "<li>Jamón</li><li>Queso</li><li>Pan</li>\n",
      "</ol>\n",
      "\n",
      "\n",
      "<li>Jamón</li>\n",
      "Jamón\n",
      "<li>Queso</li>\n",
      "Queso\n",
      "<li>Pan</li>\n",
      "Pan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<ol>\n",
      "<li>Lechuga</li><li>Tomate</li>\n",
      "</ol>\n",
      "\n",
      "\n",
      "<li>Lechuga</li>\n",
      "Lechuga\n",
      "<li>Tomate</li>\n",
      "Tomate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tPlanes para el fin de semana (sin orden):\n",
      "\t\n",
      "<ul>\n",
      "<li>Bailar</li><li>Leer</li><li>Estudiar parciales</li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "<li>Bailar</li>\n",
      "Bailar\n",
      "<li>Leer</li>\n",
      "Leer\n",
      "<li>Estudiar parciales</li>\n",
      "Estudiar parciales\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<h3> Mis títulos pueden tener diferentes niveles 3 </h3>\n",
      " Mis títulos pueden tener diferentes niveles 3 \n",
      "\n",
      "\n",
      "<h4> Mis títulos pueden tener diferentes niveles 4 </h4>\n",
      " Mis títulos pueden tener diferentes niveles 4 \n",
      "\n",
      "\n",
      "<h5> Mis títulos pueden tener diferentes niveles 5 </h5>\n",
      " Mis títulos pueden tener diferentes niveles 5 \n",
      "\n",
      "\n",
      "<h6> Mis títulos pueden tener diferentes niveles 6 </h6>\n",
      " Mis títulos pueden tener diferentes niveles 6 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encontremos los elementos de la lista\n",
    "for child in bsObj.find(\"body\").descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<h1>Mi Primer Título</h1>\n",
      "\n",
      "sssss\n",
      "\t\n",
      "<h2> También puedo generar una serie de listas</h2>\n",
      "\n",
      "\n",
      "\tLista de compras (ordenadas):\n",
      "\t\n",
      "<ol>\n",
      "<li>Jamón</li><li>Queso</li><li>Pan</li>\n",
      "</ol>\n",
      "\n",
      "\n",
      "<ol>\n",
      "<li>Lechuga</li><li>Tomate</li>\n",
      "</ol>\n",
      "\n",
      "\n",
      "\tPlanes para el fin de semana (sin orden):\n",
      "\t\n",
      "<ul>\n",
      "<li>Bailar</li><li>Leer</li><li>Estudiar parciales</li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "<h3> Mis títulos pueden tener diferentes niveles 3 </h3>\n",
      "\n",
      "\n",
      "<h4> Mis títulos pueden tener diferentes niveles 4 </h4>\n",
      "\n",
      "\n",
      "<h5> Mis títulos pueden tener diferentes niveles 5 </h5>\n",
      "\n",
      "\n",
      "<h6> Mis títulos pueden tener diferentes niveles 6 </h6>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista_alimentos = []\n",
    "for child in bsObj.find(\"body\").children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "\n",
    "* Tratemos de poner nuevamente los elementos de la primera lista en una canasta.\n",
    "\n",
    "*Nota que*: Esto puede ser un poco más complicado porque `.children` y `.descendants` retornan un iterador (solo podemos acceder a sus elementos haciendo un loop o definiendo una lista)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n",
      "<li>Jamón</li>\n",
      "<li>Queso</li>\n",
      "<li>Pan</li>\n",
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "for child in bsObj.find(\"ol\").children:\n",
    "    print(repr(child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jamón', 'Queso', 'Pan']\n"
     ]
    }
   ],
   "source": [
    "lista_alimentacion = []\n",
    "for child in bsObj.find(\"ol\").children:\n",
    "    if child == \"\\n\":\n",
    "        continue\n",
    "    else:\n",
    "        lista_alimentacion.append(child.string)\n",
    "print(lista_alimentacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inténtalo tú\n",
    "\n",
    "* Modifica el código anterior para agarrar todos los elementos de la segunda lista de la página. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<li>Lechuga</li>\n",
      "<li>Tomate</li>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for child in bsObj.findAll(\"ol\")[1].children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#No solamente descendientes e hijos... También padres y hermanos.\n",
    "\n",
    "También existen otras opciones para navegar una página y obtener lo que queremos `.parent`, `next_sibling` y `previous_sibling` nos ofrecen otras opciones.\n",
    "\n",
    "Nota que también existe `.parents`, `next_siblings` y `previous_sibling`. Al igual que `children` y `descendants` nos dará un iterable con todos los elementos que cumplan con esas condiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ol>\n",
       "<li>Jamón</li><li>Queso</li><li>Pan</li>\n",
       "</ol>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚¿Cuál será el padre de nuestro primer elemento de la lista?\n",
    "bsObj.find(\"ol\").li.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚¿Cuál será el hermano anterior de nuestro primer elemento de la lista?\n",
    "bsObj.find(\"ol\").li.previous_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li>Queso</li>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.find(\"ol\").li.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresemos a la página de Wikipedia\n",
    "\n",
    "* ¿Qué elemento es el hermano del primer elemento de la lista de coaliciones políticas?\n",
    "* Pongámoslo todo en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gana Perú'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_pag.find(\"li\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gana Perú', 'Fuerza Popular', 'Alianza por el Gran Cambio']\n"
     ]
    }
   ],
   "source": [
    "#Elementos en la lista.\n",
    "lista_coaliciones = [wiki_pag.find(\"li\").get_text()]\n",
    "for item in wiki_pag.find(\"li\").next_siblings:\n",
    "    if item == \"\\n\":\n",
    "        continue\n",
    "    else:\n",
    "        lista_coaliciones.append(item.string)\n",
    "    \n",
    "print(lista_coaliciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gente que busca gente\n",
    "\n",
    "Para terminar todas las opciones de navegación que ofrece BeutifulSoup, terminaremos con algunos criterios de búsqueda. Se acuerdan que antes usamos los métodos `.find(attrs)` y `findAll(attrs)` para encontrar algunos elementos de la página que nos interesaba... lo mismo podemos hacer para padres y hermanos. Para eso puedes usar `.find_parent(attrs)`, `.find_parents(attrs)`,  `.find_next_sibling(attrs)` o  `.find_next_siblings(attrs)`... Al igual que en el caso anterior la diferencia entre usar el método en singular y en plural radica que en el singular (i.e. `.find_parent(attrs)` y `.find_next_sibling(attrs)`) se retornará el primer elemento de la página que cumpla con las especificaciones. En los otros casos, se retornará una lista con todos aquellos elementos que cumplan con las características establecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li><a class=\"mw-redirect\" href=\"/wiki/Fuerza_2011\" title=\"Fuerza 2011\">Fuerza Popular</a></li>,\n",
       " <li><a href=\"/wiki/Alianza_por_el_Gran_Cambio\" title=\"Alianza por el Gran Cambio\">Alianza por el Gran Cambio</a></li>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_pag.find(\"li\").find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sobre la base del ejemplo anterior genera una lista que contenga todas las coaliciones. \n",
    "# ¡¡Recuerda de quitar todas las etiquetas de HTML!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Repite el ejercicio anterior para la lista ordenada de la página web 'html_basics.html'.\n",
    "1. (Medio) Trata de obtener el análisis político para la región Lima de la siguiente página: http://www.infogob.com.pe/Analisis/ubigeo.aspx?IdLocalidad=1454&IdUbigeo=140000\n",
    "1. (Difícil) ¿Cuáles son los eventos de actualidad destacados por Wikipedia?\n",
    "1. (Difícil) Entra a la página web de Wikipedia y obtén la lista de fallecidos del día. Asegúrate de solo obtener el nombre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cómo obtener toda la tabla\n",
    "\n",
    "Hasta ahora solo hemos ubicado ciertos elementos de la tabla, sin embargo nostros queremos agarrar toda la tabla. Veamos cómo hacerlo siguiendo el ejemplo de la tabla de partidos políticos de wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Acción Popular', '4 de agosto de 2004', '1956', 'www.accionpopular.com.pe'], ['Alianza para el Progreso', '12 de febrero de 2008', '2001', 'www.app-peru.org.pe'], ['Democracia Directa', '11 de diciembre de 2013', '', 'fonavismodemocraciadirecta.blogspot.com'], ['Fuerza Popular', '9 de marzo de 2010', '2010', 'www.fuerzapopular.pe'], ['Orden', '', '', ''], ['Partido Aprista Peruano', '31 de enero de 2005', '1924', 'apra.com.pe'], ['Partido Democrático Somos Perú', '22 de noviembre de 2004', '1997', '[1]'], ['Partido Humanista Peruano', '23 de noviembre de 2009', '2001', '[2]'], ['Partido Nacionalista Peruano', '4 de enero de 2006', '2005', '[3]'], ['Partido Popular Cristiano', '29 de noviembre de 2004', '1966', 'ppc.pe'], ['Perú Patria Segura', '18 de marzo de 2005', '1989', '[4]'], ['Perú Posible', '14 de marzo de 2005', '1994', '[5]'], ['Peruanos Por el Kambio', '', '', 'http://ppk.pe/'], ['Restauración Nacional', '24 de noviembre de 2005', '2005', '[6]'], ['Siempre Unidos', '21 de febrero de 2008', '2008', 'http://siempreunidos.org.pe/portal/'], ['Solidaridad Nacional', '7 de diciembre de 2004', '1999', 'http://solidaridadnacional.pe/'], ['Tierra y Libertad', '16 de marzo de 2012', '2012', ''], ['Todos por el Perú', '4 de enero de 2005', '', 'http://todosporelperu.pe/'], ['Unión por el Perú', '7 de marzo de 2005', '1994', ''], ['Vamos Perú', '27 de septiembre de 2013', '2013', '']]\n"
     ]
    }
   ],
   "source": [
    "tabla_partidos = []\n",
    "for item in wiki_pag.findAll(\"tr\"):\n",
    "    try:\n",
    "        tabla_partidos.append(item.find_next_sibling().findAll(\"td\"))\n",
    "    except AttributeError:\n",
    "        continue\n",
    "\n",
    "tabla_partidos_limpia = []\n",
    "\n",
    "for item in wiki_pag.findAll(\"tr\"):\n",
    "    try:\n",
    "        lista_parcial = []\n",
    "        for item in item.find_next_sibling().findAll(\"td\"):\n",
    "            lista_parcial.append(item.get_text())\n",
    "        tabla_partidos_limpia.append(lista_parcial)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "\n",
    "print(tabla_partidos_limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
